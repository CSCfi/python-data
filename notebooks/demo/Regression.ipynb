{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "For an overview on regression see [Wikipedia](https://en.wikipedia.org/wiki/Regression_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets, linear_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Demo\n",
    "This is a visual demo of a regression on a single variable. It is from [Scikit-learn documentation](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html).\n",
    "\n",
    "Two [quality of fit metrics](http://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) are also computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Variance score: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.4/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADtCAYAAAAcNaZ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGCJ0AcAQoQsAhv4PoxIe5I/wL7QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f6e345fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "%matplotlib inline\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((regr.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Regression\n",
    "\n",
    "We will demonstrate regression with an automatically generated example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y, coef = make_regression(n_samples = 300, n_features=30, \n",
    "                             n_informative=4, noise=1.5,\n",
    "                             bias=0.1, \n",
    "                             coef=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "The simplest regression model is a [linear one](https://en.wikipedia.org/wiki/Linear_regression). It's also the one used in the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99829272971844885"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = linear_model.LinearRegression()\n",
    "regressor.fit(X_train, Y_train)\n",
    "regressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.          28.58845312   0.           0.           0.           0.           0.\n",
      "   0.           0.          11.93077114   0.           0.           0.           0.\n",
      "  24.04775151   0.           0.           0.           0.           0.           0.\n",
      "  15.79860234   0.           0.           0.           0.           0.           0.\n",
      "   0.           0.        ]\n",
      "[ -2.05411570e-02   2.85977512e+01   1.57651729e-02  -5.25536059e-02\n",
      "  -1.03088219e-01  -1.38872587e-01   9.50227868e-02  -1.81823686e-01\n",
      "   5.73814482e-02   1.20936988e+01  -1.11925413e-01  -9.07402213e-02\n",
      "   9.42494840e-02  -6.30044821e-02   2.40471663e+01   1.72958983e-01\n",
      "  -1.15757755e-01  -5.06785722e-02   8.31488731e-02  -6.42454465e-02\n",
      "   1.79464476e-03   1.57583120e+01  -1.79175685e-02  -2.63467931e-03\n",
      "  -3.51440240e-02   1.30071064e-01   1.05410687e-01   1.12320521e-02\n",
      "   1.69295954e-01  -2.41883029e-01]\n"
     ]
    }
   ],
   "source": [
    "# Because we created the model we can compare the coefficients\n",
    "print(coef)\n",
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector regression\n",
    "\n",
    "A more powerful paradigm is [support vector regression](https://en.wikipedia.org/wiki/Support_vector_machine#Regression) . It can perform better than linear regression but for instance in this case it doesn't. If chosen methods perform equally one should choose the simpler one or the one that makes less assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99814101957195134"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "regressor = SVR(kernel=\"linear\")\n",
    "regressor.fit(X_train, Y_train)\n",
    "regressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Trick\n",
    "\n",
    "It's usually possible to make a linear regressor or classifier into a nonlinear one using the [kernel trick](https://en.wikipedia.org/wiki/Kernel_method). The fancy name essentially means that a nonlinear transformation is made before applying a linear method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09014455611746075"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = SVR(kernel=\"rbf\")\n",
    "regressor.fit(X_train, Y_train)\n",
    "regressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "\n",
    "If there's reason to believe that only a subset of the data will be relevant to the regression, the [Lasso algorithm](https://en.wikipedia.org/wiki/Lasso_%28statistics%29) is a staple to use to drop irrelevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99651160053710619"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "regressor = Lasso()\n",
    "regressor.fit(X_train, Y_train)\n",
    "regressor.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.        ,  27.51293275,  -0.        ,  -0.        ,\n",
       "         0.        ,  -0.        ,   0.        ,  -0.        ,\n",
       "         0.        ,  11.15433248,   0.        ,  -0.        ,\n",
       "        -0.        ,   0.        ,  23.15822334,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ,  -0.        ,\n",
       "        -0.        ,  14.76663532,  -0.        ,   0.        ,\n",
       "        -0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,  -0.        ])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see how lasso gets the 0 coefficients to actually 0 and not very close\n",
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Boston house prices\n",
    "\n",
    "\n",
    "The goal in the Boston house prices datasets is to predict the median value of house prices in an area using other data about the area.\n",
    "\n",
    "Go ahead and try to predict the house prices using the example methods given or a method of your own choosing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "house_prices = datasets.load_boston()\n",
    "print(house_prices.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes data\n",
    "\n",
    "The diabetes dataset consists of measurements from users and a \n",
    "quantitative value representing their state one year from the measurements. The goal is to predict their state one year from now based on the values.\n",
    "\n",
    "See more info [here](http://scikit-learn.org/stable/datasets/index.html#diabetes-dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "#the diabetes dataset doesn't contain a written description so see the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
